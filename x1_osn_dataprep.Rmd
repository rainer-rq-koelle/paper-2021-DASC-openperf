---
title: "Trajectory Processing"
author: "PRU"
date: "14/07/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(readr)
library(arrow)
library(dplyr)
library(purrr)
library(tidyr)
library(sf)
library(sftrack)
library(geosphere)
library(trrrj)
library(h3)

source("./R/make_nice_names_trafficlib.R")
source('./R/make_unique_id.R')
source('./R/remove_orphans.R')
source('./R/extract_4d_nest.R')
source('./R/confirm_arrival_at.R')
source('./R/cast_sf_utils.R')
source('./R/rwy_system.R')
source('./R/identify_runway.R')
source('./R/estimate_threshold_time.R')
source('./R/calc_crossing.R')
```

## Overview

This Rmd documents the data preparatory steps following the data exploratory stage (c.f. x0_eda ...Rmd).
The focus is on cleaning the eda utility functions to establish the analytic data required for this study.


```{r}
#apt <- "EGLL"
#fns <- list.files(path = "./data-raw/", pattern = paste0(apt,".*\\.feather"), full.names = TRUE)


study_loop <- function(.apt, .fn, .debug = FALSE){
  
# ---------------------- read in airport data --------------------------------  
aip <- readr::read_csv("./data/aip.csv") %>%
  filter(ICAO == .apt)

# ---------------------- load trajectory data --------------------------------
warning(paste(.apt, " - reading - ", .fn))
ds <- read_feather(.fn) %>% as_tibble()

ds <- ds %>% 
  make_nice_names_trafficlib() %>%
  make_unique_id() %>% 
  remove_orphans(500)

meta <- ds %>% group_by(UID) %>% 
  summarise(N = n(), ADEP = unique(ADEP), ADES = unique(ADES)
            ,START = unique(start[!is.na(start)])
            , STOP = unique(stop [!is.na(stop )]) )


# ----------------------- label arrival traffic -------------------------------
phase <- ds %>% 
  extract_4d_nest() %>%
  confirm_arrival_at(aip %>% rwy_system_hull(7000))

meta <- meta %>% left_join(phase %>% select(UID, ARR), by = "UID")

# ---------------------- determine landing runway -----------------------------
rwy_ctr_line_ls <- aip %>% 
  rwy_ctr_line() %>% 
  rwy_ctr_line_pts() %>% 
  cast_latlon_to_pts() %>% cast_pts_to_ls(REF)

arrs <- phase %>% filter(ARR == TRUE) %>%
  
  mutate( rwy = map(.x = last_4d, .f = ~identify_rwy(.x %>% cast_latlon_to_pts() , rwy_ctr_line_ls))
         ,RWY = map(.x = rwy, .f = ~.x %>% filter(TRUST == max(TRUST)) %>% pull(REF))
  ) %>% 
  tidyr::unnest(RWY)

meta <- meta %>% left_join(arrs %>% select(UID, RWY), by = "UID")

# ----------------------- determine threshold time ----------------------------
thrt <- arrs %>% 
  # append runway coordinates
  left_join(aip %>% 
              filter(TYPE == "THR") %>% 
              select(RWY = REF, LAT_THR = LAT, LON_THR = LON)
            , by = "RWY"
            ) %>%
  
  unnest(last_4d) %>% group_by(UID) %>% nest() %>% 
  mutate(THR_TIME = map(.x = data, .f= ~ estimate_threshold_time(.x))
         ) %>% 
  unnest(THR_TIME)

arrs <- arrs %>% left_join(thrt %>% select(UID, THR_TIME), by = "UID")

# ----------------------- determine ASMA crossings ----------------------------
asma <- arrs %>% select(UID, data)  
arp  <- aip %>% filter(TYPE == "ARP") %>% df_to_geo_lonlat()

asma <- asma %>% 
  mutate(
    C40 = map( .x = data
              ,.f = ~ extract_pos_at_distance_from_point(.x, .pt = arp , .dist = 40)
            )
    ,C50= map( .x = data
              ,.f = ~ extract_pos_at_distance_from_point(.x, .pt = arp , .dist = 50)
            )
    ,C100= map( .x = data
              ,.f = ~ extract_pos_at_distance_from_point(.x, .pt = arp , .dist = 100)
            )
  ) %>%
  unnest(cols = contains("C"))

arrs <- arrs %>% select(-c(data, last_4d, rwy)) %>%
  left_join(asma %>% select(-data), by = "UID")

# ---------------------- package and write out data ---------------------------
prefix <- .fn %>% stringr::str_split(pattern = "_") %>% unlist()
prefix <- prefix[2]  # grab date
prefix <- paste0(apt, "-", prefix, "-")

print( message(paste0("... writing files for ", prefix)) )
write_csv(meta, file = paste0("./data/", prefix, "meta.csv"))
write_csv(arrs, file = paste0("./data/", prefix, "asma.csv"))

if(.debug)return(list(meta = meta, arrs = arrs))
}
```

```{r, eval=FALSE}
# apt <- "EGLL"
apt <- "EHAM"
fns <- list.files(path = paste0("./data-raw/",apt,"/"), pattern = paste0(apt,".*\\.feather"), full.names = TRUE)

study_loop(.apt = apt, .fn = fns[1])
```

```{r, message=FALSE}
apt <- "EHAM"
fns <- list.files(path = paste0("./data-raw/",apt, "/"), pattern = paste0(apt,".*\\.feather"), full.names = TRUE)
#2nd run: fns <- fns[167:185]
# itr <- expand.grid(APT = apt, FN = fns) %>% as_tibble()
fns <- fns[2:185]
purrr::pmap(.l = list(apt = apt, fn = fns), .f = ~ study_loop(.apt = ..1, .fn = ..2))
```


Geographic indexing

```{r}
study_index <- function(.apt, .fn, .debug = NULL){
  
# ---------------------- read in airport data --------------------------------  
aip <- readr::read_csv("./data/aip.csv") %>%
  filter(ICAO == .apt) %>%
  select(RWY = REF, LAT, LON, TYPE)

# ---------------------- get landing runway & thr time -----------------------

what_date <- .fn %>% 
  stringr::str_split(pattern = "_") %>% 
  lubridate::parse_date_time("ymd")

asma_fn <- paste0("./data/", apt, "-", what_date, "-asma.csv")

ldgs <- readr::read_csv( asma_fn
                        ,col_types = cols_only( UID = col_character()
                                          ,ARR = col_logical()
                                          ,RWY = col_character()
                                          ,THR_TIME = col_datetime()
                                          )
                        )
ldgs <- ldgs %>% left_join(aip, by = "RWY")

# ---------------------- load trajectory data --------------------------------
ds <- read_feather(.fn) %>% as_tibble()

ds <- ds %>%
  make_nice_names_trafficlib() %>%
  make_unique_id() %>%
  remove_orphans(500)

ds <- ds %>%
  left_join(ldgs %>% select(UID, RWY, THR_TIME), by = "UID") %>%
  select(UID, TIME, LAT, LON, RWY, THR_TIME) %>%
  group_by(UID) %>%
  filter(TIME <= THR_TIME) %>%   # cut trajectory data to before threshold
  ungroup()

ds <- ds %>%
  bind_rows(ldgs %>% rename(TIME = THR_TIME) %>% select(-ARR)) %>%
  select(-THR_TIME) %>%           # remove unused column
  group_by(UID) %>%
  arrange(desc(TIME), .by_group = TRUE) %>% 
#------------------------  trrrj cum time and cum distance
  rename(latitude = LAT, longitude = LON, timestamp = TIME) %>% 
  cumulative_distance() %>%
  cumulative_time() %>%
  rename( TIME = timestamp, LAT = latitude, LON = longitude
         ,DIST_2GO = cumulative_distance, TIME_2GO = cumulative_time ) %>%
  mutate(TIME_2GO = - TIME_2GO) %>%     # correct sign
  ungroup()

# ---------------------- geographic indexing
ds <- ds %>%
   mutate(H3_BIN = geo_to_h3(c(LAT, LON), res = 8))

bins <- ds %>% group_by(H3_BIN, RWY) %>%
   summarise( N = n()
             ,MIN_DIST_2GO = min(DIST_2GO) , MIN_TIME_2GO = min(TIME_2GO)
             ,P20_DIST_2GO = quantile(DIST_2GO, probs = 0.2), P20_TIME_2GO = quantile(TIME_2GO, probs = 0.2)
             ,AVG_DIST_2GO = mean(DIST_2GO), AVG_TIME_2GO = mean(TIME_2GO)
             ,MAX_DIST_2GO = max(DIST_2GO) , MAX_TIME_2GO = max(TIME_2GO)
             ,.groups = "drop") %>%
  mutate(DOF = what_date)

warning(paste0("writing bins for ", what_date, " - ", .apt))
bin_fn <- paste0("./data/", .apt, "-", what_date, "-bins.csv")
write_csv(bins, file = bin_fn)

if(.debug) return(list(ds, bins))
}

```

```{r}
apt <- "EGLL"
fns <- list.files(path = "./data-raw/", pattern = paste0(apt,".*\\.feather"), full.names = TRUE)

(rq <- study_index(apt, fns[1]))
```


